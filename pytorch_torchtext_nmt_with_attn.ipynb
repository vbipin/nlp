{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/vbipin/nlp/blob/master/pytorch_nmt_with_attn.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "H1YKD0ecH5YL",
    "outputId": "fcf5deed-9c58-455d-9bff-c6507633237b"
   },
   "outputs": [],
   "source": [
    "### !pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QpAQoWoIH9R1"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wn6npWWAIlfD"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDkn1YIHI45t"
   },
   "outputs": [],
   "source": [
    "#This notebook is adapted from\n",
    "##http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sUfcLWs4JJKv"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#for monitoring\n",
    "from time import time\n",
    "#for parsing the data filename\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we prepare data directly form the web link. It is useful in Colab notebooks\n",
    "#to convert to script\n",
    "#jupyter nbconvert --to script [YOUR_NOTEBOOK].ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we need the data from : http://www.manythings.org/anki/fra-eng.zip\n",
    "import requests\n",
    "import gzip\n",
    "import io\n",
    "import zipfile\n",
    "\n",
    "#get the contents from the website\n",
    "\"\"\"r = requests.get('http://www.manythings.org/anki/fra-eng.zip')\"\"\"\n",
    "\n",
    "#this is one ugly code; But I need the text from a zip file in a url :(((\n",
    "#https://stackoverflow.com/questions/37704836/how-do-i-read-a-csv-file-thats-gzipped-from-url-python\n",
    "#https://codeyarns.com/2013/10/03/how-to-read-contents-of-zip-file-in-python/\n",
    "#https://docs.python.org/2/library/zipfile.html\n",
    "\"\"\"\n",
    "with zipfile.ZipFile( io.BytesIO(r.content), mode='r' ) as zip_file :\n",
    "  print (zip_file.namelist())\n",
    "  lines = zip_file.read('fra.txt').strip().split(b'\\n')\n",
    "  lines = [ str(l, 'utf-8') for l in lines ]\n",
    "  print(len(lines))\n",
    "\"\"\"\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we have the lines form a file; create it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XimE1ug_JPu8"
   },
   "outputs": [],
   "source": [
    "#This class is from the pytorch tutorial. \n",
    "#it holds thevocab and index convertions\n",
    "\n",
    "#XXX TODO: May be use torchtext\n",
    "\n",
    "UNK_token = 0\n",
    "PAD_token = 1\n",
    "SOS_token = 2\n",
    "EOS_token = 3\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.stoi = {\"<unk>\":UNK_token, \"<pad>\":PAD_token, \"<sos>\" :SOS_token, \"<eos>\" :EOS_token}\n",
    "        self.itos = {UNK_token:\"<unk>\", PAD_token:\"<pad>\", SOS_token: \"<sos>\", EOS_token: \"<eos>\"}\n",
    "        self.n_words = len(self.stoi)  # Count SOS and EOS\n",
    "        self.SOS_token = SOS_token\n",
    "        self.EOS_token = EOS_token\n",
    "        self.word2count = {}\n",
    "        self.vocab = self.stoi\n",
    "\n",
    "    def add_line(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.stoi:\n",
    "            self.stoi[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.itos[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DaS5g1e6JWhF"
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)     #add a space\n",
    "    s = re.sub(r\"[^a-zA-Z.!?']+\", r\" \", s) #only these; others are spaces\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "to929YspJZAP"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "#m = re.search( '(...)-(...)\\.txt', 'eng-fra.txt')\n",
    "#m.group(2)\n",
    "class Data__ :\n",
    "    def __init__(self, src_lines, trg_lines,max_len=35, n_data=None ) :\n",
    "        \n",
    "        if n_data : #we only consider that many lines  \n",
    "            self.src_lines = src_lines[0:n_data]\n",
    "            self.trg_lines = trg_lines[0:n_data]\n",
    "        else :\n",
    "            self.src_lines = src_lines\n",
    "            self.trg_lines = trg_lines\n",
    "            \n",
    "        self.src_lang = Lang('src') #for each language counts etc\n",
    "        self.trg_lang = Lang('trg')\n",
    "        #self.src_lang = src_lang #for each language counts etc\n",
    "        #self.trg_lang = trg_lang\n",
    "        \n",
    "        for s in self.src_lines :\n",
    "            self.src_lang.add_line(s)\n",
    "            \n",
    "        for t in self.trg_lines :\n",
    "            self.trg_lang.add_line(t)\n",
    "            \n",
    "        #self.seq_len = 1\n",
    "        self.batch_size = 1\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        #to tensor\n",
    "        self.src_tensors = torch.stack( [ self.line_to_tensor(self.src_lang, s) for s in self.src_lines ] ).to(device)\n",
    "        self.trg_tensors = torch.stack( [ self.line_to_tensor(self.trg_lang, t) for t in self.trg_lines ] ).to(device)\n",
    "        \n",
    "        \n",
    "    def word_to_tensor(self, word, lang=None ) :\n",
    "        if not lang :\n",
    "            lang = self.trg_lang\n",
    "        return torch.LongTensor( [lang.stoi[word]] ).view(-1,1).to(device)\n",
    "    \n",
    "    def index_to_tensor(self, index) :\n",
    "        return torch.LongTensor( [index] ).view(-1,1).to(device)\n",
    "        \n",
    "    def line_to_tensor(self, lang, sentence):\n",
    "        idxs = [lang.stoi[word] for word in sentence.split(' ')]\n",
    "        #idxs.append( lang.EOS_token ) # this is the EOS token\n",
    "        length = len(idxs)\n",
    "        extend = self.max_len - length - 1 #we take out the lebth and start token and extend that much EOS token\n",
    "        idxs = [lang.SOS_token] + idxs + [lang.EOS_token] * extend\n",
    "        return torch.LongTensor(idxs)\n",
    "            \n",
    "    def train_batch(self, n_data=1000, random=True) : #we return the torchtensor inputs to embedding layers\n",
    "        N = len(self.src_lines)\n",
    "        r_indexs = np.random.randint(N, size=n_data)\n",
    "        for i in r_indexs :\n",
    "            yield self.src_tensors[i].view(-1,1 ), self.trg_tensors[i].view(-1,1 )\n",
    "            #yield st.to(device), dt.to(device)\n",
    "            \n",
    "    def batch__(self, batch_size=1) : #we return the torchtensor inputs to embedding layers\n",
    "        for s,d in self.pairs : \n",
    "            st = self.line_to_tensor(self.src,  s).view(-1,1 ) #seq_length, index (n,1)\n",
    "            dt = self.line_to_tensor(self.dest, d).view(-1,1 )#batch need to be handled later\n",
    "            yield st.to(device), dt.to(device)\n",
    "    \n",
    "    def batch_(self, n_data=1000, random=True) : #we return the torchtensor inputs to embedding layers\n",
    "        #first we create n_size random indexes for 0 to N\n",
    "        N = len(self.pairs)\n",
    "        r_indexs = np.random.randint(N, size=n_data)\n",
    "        for i in r_indexs :\n",
    "            s,d = self.pairs[i] \n",
    "            st = self.line_to_tensor(self.src,  s).view(-1,1 ) #seq_length, index (n,1)\n",
    "            dt = self.line_to_tensor(self.dest, d).view(-1,1 )#batch need to be handled later\n",
    "            yield st.to(device), dt.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from: https://github.com/pytorch/text/blob/master/test/translation.py\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "url = re.compile('(<url>.*</url>)')\n",
    "\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(url.sub('@URL@', text))]\n",
    "\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(url.sub('@URL@', text))]\n",
    "    \n",
    "    \n",
    "# Testing custom paths\n",
    "DE = data.Field(tokenize=tokenize_de)\n",
    "EN = data.Field(tokenize=tokenize_en)\n",
    "\n",
    "train, val = datasets.TranslationDataset.splits(\n",
    "    path='.data/multi30k/', train='train',\n",
    "    validation='val', exts=('.de', '.en'),\n",
    "    fields=(DE, EN))\n",
    "\n",
    "print(train.fields)\n",
    "print(len(train))\n",
    "print(vars(train[0]))\n",
    "print(vars(train[100]))\n",
    "\n",
    "DE.build_vocab(train.src, min_freq=3)\n",
    "EN.build_vocab(train.trg, max_size=50000)\n",
    "\n",
    "train_iter, val_iter = data.BucketIterator.splits(\n",
    "    (train, val), batch_size=3)\n",
    "\n",
    "print(DE.vocab.freqs.most_common(10))\n",
    "print(len(DE.vocab))\n",
    "print(EN.vocab.freqs.most_common(10))\n",
    "print(len(EN.vocab))\n",
    "\n",
    "batch = next(iter(train_iter))\n",
    "print(batch.src)\n",
    "print(batch.trg)\n",
    "\"\"\"\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data class usnign torchtext\n",
    "#from: https://github.com/pytorch/text/blob/master/test/translation.py\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from torchtext import datasets\n",
    "from torchtext import data\n",
    "from torchtext.data import Field\n",
    "\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "url = re.compile('(<url>.*</url>)')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(url.sub('@URL@', text))]\n",
    "\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(url.sub('@URL@', text))]\n",
    "\n",
    "class Data :\n",
    "    def __init__(self, batch_size=1) :\n",
    "        DE = data.Field(tokenize=tokenize_de, init_token=\"<sos>\", eos_token=\"<eos>\" )\n",
    "        EN = data.Field(tokenize=tokenize_en, init_token=\"<sos>\", eos_token=\"<eos>\" )\n",
    "        self.train, self.val,self.test = datasets.TranslationDataset.splits(\n",
    "                path='data/multi30k/', train='train',\n",
    "                validation='val', exts=('.de', '.en'),\n",
    "                fields=(DE, EN))\n",
    "        DE.build_vocab(self.train.src,  min_freq=3) #specials=['<sos>','<eos>','<unk>','<pad>'],\n",
    "        EN.build_vocab(self.train.trg,  max_size=50000) #specials=['<sos>','<eos>','<unk>','<pad>'],\n",
    "        \n",
    "        self.src_lang = DE\n",
    "        self.trg_lang = EN\n",
    "        \n",
    "        self.train_iter, self.val_iter = data.BucketIterator.splits((self.train,self.val), batch_size=batch_size)\n",
    "\n",
    "\n",
    "    def train_batch(self) :\n",
    "        for batch in itertools.islice(self.train_iter,0,len(self.train_iter)) :\n",
    "            yield batch.src, batch.trg\n",
    "        \n",
    "    def val_batch(self) :\n",
    "        for batch in itertools.islice(self.val_iter,0,len(self.val_iter)) :\n",
    "            yield batch.src, batch.trg    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_de = open(\"data/multi30k/val.de\", encoding='utf-8').read().strip().split('\\n')\n",
    "lines_en = open(\"data/multi30k/val.en\", encoding='utf-8').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines = [ (normalize_string(lines_de[i]), normalize_string(lines_en[i])) for i in range(len(lines_de)) ]\n",
    "#len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#German to English\n",
    "#multi30k_data__ = Data__(lines_de, lines_en, max_len=35 )\n",
    "multi30k_data = Data()\n",
    "#print(random.choice(data.pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi30k_data__ = Data__(lines_de, lines_en, max_len=35 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data.BucketIterator.splits( (multi30k_data.train,multi30k_data.val), repeat=None, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Iv1mj57Z5wSu",
    "outputId": "a9d0a6bc-7d0b-43e1-b33a-e24b6935dd70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29000\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in itertools.islice(a[0],0,len(a[0])) :\n",
    "    c += 1\n",
    "    if c > 30000 :\n",
    "        break\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bzl4TVrG9kqS"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, src_vocab_size, hidden_size, num_layers=1 ):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        #embedding vector size is fixed as hidden size\n",
    "        self.enbedding_vector_size = hidden_size\n",
    "        self.embedding = nn.Embedding(src_vocab_size, self.enbedding_vector_size )\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(-1)\n",
    "        output = embedded.view( input.shape[0], 1, -1 ) #seq_length, batch, enbbding\n",
    "        #print (output.shape)\n",
    "        #print (hidden.shape)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7F8gYijaAgbN"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, dest_vocab_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        #embedding vector size is fixed as hidden size\n",
    "        self.enbedding_vector_size = hidden_size\n",
    "        self.embedding = nn.Embedding(dest_vocab_size, self.enbedding_vector_size )\n",
    "        \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size, dest_vocab_size)\n",
    "        #self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(-1)\n",
    "        #output = F.relu(output)\n",
    "        output = embedded.view( input.shape[0], 1, -1 ) #input shape[0] is 1 as wqe feed one input at a time.\n",
    "        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.linear( output.squeeze() )\n",
    "        #print (output.shape)\n",
    "        output = F.log_softmax( output, dim=0 )\n",
    "        return output.view(1,-1), hidden #output of shape N,C; here N=1\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8E_DKBJ5AjkK"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 50\n",
    "\n",
    "class Attn(nn.Module) :\n",
    "    def __init__(self, hidden_size, max_length) :\n",
    "        super(Attn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_length = max_length\n",
    "        self.linear = nn.Linear(self.hidden_size, self.max_length)\n",
    "        \n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs) :\n",
    "        \n",
    "        attn_scores = self.linear(hidden)\n",
    "        #print(\"attn_scores\", attn_scores.shape )\n",
    "                \n",
    "        attn_weights = F.softmax(attn_scores, dim=2)\n",
    "        \n",
    "        #print(\"attn_weights\", attn_weights.shape)\n",
    "        #print(\"encoder_outputs\",encoder_outputs.shape)\n",
    "        \n",
    "        attn_applied = torch.matmul(attn_weights.squeeze(),encoder_outputs)\n",
    "        #print (\"attn_applied \", attn_applied.shape)\n",
    "        \n",
    "        return attn_applied, attn_weights\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        #embedding vector size is fixed as hidden size\n",
    "        self.enbedding_vector_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.enbedding_vector_size)\n",
    "        \n",
    "        self.attn = Attn(self.hidden_size, self.max_length)\n",
    "        #self.attn = nn.Linear(self.hidden_size, self.max_length)        \n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        #self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        \"\"\"input is an index of the word. We create a word vector out of it\"\"\"\n",
    "        embedded = self.embedding(input) \n",
    "        #print(\"embedded\", embedded.shape )\n",
    "                \n",
    "        \"\"\" gru hidden has shape (num_layers * num_dir, batch, hidden_size)\n",
    "            Here first two dim are 1\n",
    "        \"\"\"\n",
    "        output, hidden = self.gru(embedded.view(1,1,-1), hidden)\n",
    "        #print (\"hidden \", hidden.shape)\n",
    "        \n",
    "        #linear W.h \n",
    "        #out (max, )\n",
    "        attn_context, attn_weights = self.attn( hidden, encoder_outputs)\n",
    "        #print (\"attn_context \", attn_context.shape)\n",
    "        \n",
    "        \n",
    "        output = torch.cat((hidden.view(1,-1), attn_context.view(1,-1)), 1)\n",
    "        #print (\"output \", output.shape) \n",
    "        \n",
    "        output = self.attn_combine(output)\n",
    "        #print (\"output \", output.shape)        \n",
    "        output = F.relu(output) #h tilde\n",
    "        #print (\"output \", output.shape)\n",
    "        \n",
    "        #output = F.log_softmax(self.out(output), dim=1)\n",
    "        output = self.out(output)\n",
    "        #print (\"output \", output.shape)\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-SJIEKfqAoVR"
   },
   "outputs": [],
   "source": [
    "#debug_list = []\n",
    "def translate( encoder, decoder, in_data, input_sentence ) :\n",
    "    debug_list = [] #XXX\n",
    "    x = in_data.line_to_tensor( in_data.src_lang, input_sentence ).to(device)\n",
    "    h = encoder.initHidden().to(device)\n",
    "    out, h = encoder(x, h)\n",
    "    g = h\n",
    "    \n",
    "    encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_size, device=device)\n",
    "    for i in range(out.shape[0]) :\n",
    "        encoder_outputs[i] = out[i][0]\n",
    "        \n",
    "    #first input is SOS\n",
    "    next_word = in_data.index_to_tensor( in_data.trg_lang.SOS_token ).to(device)\n",
    "    predicted_target = []\n",
    "    for _ in range(25) :        \n",
    "        scores, g, attn_w = decoder( next_word, g, encoder_outputs )\n",
    "        #debug_list.append(attn_w)\n",
    "        if next_word.item() == in_data.trg_lang.EOS_token :\n",
    "            break\n",
    "        predicted_target.append( next_word.item() )\n",
    "        #now we make the next_word from current_word\n",
    "        v, next_word = scores.topk(1) #return value and index\n",
    "        #new_word = data.index_to_tensor( next_word )\n",
    "        #next_word = torch.multinomial( torch.exp(scores), 1 )[0]\n",
    "        #next_word = torch.multinomial( scores, 1 )[0]\n",
    "        \n",
    "        \n",
    "    return \" \".join([ in_data.trg_lang.itos[i] for i in predicted_target ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug_list = []\n",
    "def translate2( encoder, decoder, x ) :\n",
    "    debug_list = [] #XXX\n",
    "    x = x.to(device)\n",
    "    h = encoder.initHidden().to(device)\n",
    "    out, h = encoder(x, h)\n",
    "    g = h\n",
    "    \n",
    "    encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_size, device=device)\n",
    "    for i in range(out.shape[0]) :\n",
    "        encoder_outputs[i] = out[i][0]\n",
    "        \n",
    "    #first input is SOS\n",
    "    #next_word = in_data.index_to_tensor( in_data.trg_lang.SOS_token ).to(device)\n",
    "    next_word = x[0]\n",
    "    predicted_target = []\n",
    "    for _ in range(25) :        \n",
    "        scores, g, attn_w = decoder( next_word, g, encoder_outputs )\n",
    "        #debug_list.append(attn_w)\n",
    "        #if next_word.item() == in_data.trg_lang.EOS_token :\n",
    "        #    break\n",
    "        predicted_target.append( next_word.item() )\n",
    "        if next_word.item() == 3 : #in_data.trg_lang.EOS_token :\n",
    "            break\n",
    "        #now we make the next_word from current_word\n",
    "        v, next_word = scores.topk(1) #return value and index\n",
    "        #new_word = data.index_to_tensor( next_word )\n",
    "        #next_word = torch.multinomial( torch.exp(scores), 1 )[0]\n",
    "        #next_word = torch.multinomial( scores, 1 )[0]\n",
    "        \n",
    "    return predicted_target    \n",
    "    #return \" \".join([ in_data.trg_lang.itos[i] for i in predicted_target ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eAefxwrWA8mL"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 50\n",
    "def train(encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, n_data=5000 ) :\n",
    "    start = time()\n",
    "    #batch = multi30k_data.batch(n_data=n_data, random=True)\n",
    "    train_iter = multi30k_data.train_batch()\n",
    "    \n",
    "    loss_db = []\n",
    "    for x, y in train_iter :\n",
    "        loss = 0\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        h = encoder.initHidden().to(device)\n",
    "        h.detach_()\n",
    "\n",
    "        out, h = encoder(x, h)\n",
    "        g = h\n",
    "\n",
    "        encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_size, device=device)\n",
    "        for i in range(out.shape[0]) :\n",
    "            encoder_outputs[i] = out[i][0]\n",
    "    \n",
    "        for i in range(len(y) - 1) :\n",
    "        #for i in range(1) :\n",
    "            scores, g, attn_w = decoder( y[i], g, encoder_outputs )\n",
    "            #print(scores.shape)\n",
    "            #print(next_word.shape)\n",
    "            \n",
    "            loss += criterion(scores, y[i+1] )\n",
    "            #next_word = sample_from_scores( scores )  \n",
    "            #next_word = sample_from_softmax( scores )\n",
    "\n",
    "            #next_word = data.index_to_tensor( next_word )\n",
    "\n",
    "        loss.backward()\n",
    "        loss_db.append( float(loss) )\n",
    "        \n",
    "        decoder_optimizer.step()\n",
    "        encoder_optimizer.step()\n",
    "        if n_data < 0 :\n",
    "            break\n",
    "        else :\n",
    "            n_data -= 1\n",
    "        \n",
    "    end = time()\n",
    "    print (end-start)\n",
    "    return loss_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "Jl135e7-Ar-U",
    "outputId": "282ffa66-6fb7-4734-99d5-137d2273e0ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(5499, 256)\n",
      "  (gru): GRU(256, 256)\n",
      ")\n",
      "AttnDecoderRNN(\n",
      "  (embedding): Embedding(10839, 256)\n",
      "  (attn): Attn(\n",
      "    (linear): Linear(in_features=256, out_features=50, bias=True)\n",
      "  )\n",
      "  (attn_combine): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (gru): GRU(256, 256)\n",
      "  (out): Linear(in_features=256, out_features=10839, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(len(multi30k_data.src_lang.vocab), hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, len(multi30k_data.trg_lang.vocab) ).to(device)\n",
    "\n",
    "print(encoder)\n",
    "print(decoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "#criterion = nn.NLLLoss().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "y1QUXIJOA1XO",
    "outputId": "e514b108-6037-4473-c246-f0ec69bd09ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1374.4195108413696\n",
      "1322.822353363037\n",
      "1319.3825006484985\n",
      "1373.4489977359772\n",
      "1391.1451768875122\n",
      "1349.3136959075928\n",
      "1334.6806581020355\n",
      "1321.6608390808105\n",
      "1301.8802342414856\n",
      "1304.4183068275452\n",
      "1348.5517024993896\n",
      "1390.724087715149\n",
      "1367.95924949646\n",
      "1388.0935187339783\n",
      "1381.2856509685516\n",
      "1373.051774263382\n",
      "1365.1479890346527\n",
      "1357.1259396076202\n",
      "1378.8559443950653\n",
      "1337.110446214676\n"
     ]
    }
   ],
   "source": [
    "avg_loss = []\n",
    "for _ in range(20) :\n",
    "    l = train(encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, n_data=25000 )\n",
    "    avg_loss.append( np.mean(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "Vwrih715BCtO",
    "outputId": "28f1e505-027a-4c0d-9bf5-ece32a3ec9dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f041223b5f8>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(encoder.state_dict(), 'encoder.pt')\n",
    "#torch.save(decoder.state_dict(), 'decoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5mf8Uw7-BUv1",
    "outputId": "ecbd0add-e65a-4659-c8e9-071b54dfd0cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> Kids are riding a swinging carnival ride <eos>\n",
      "<sos> Children are racing in a metal setting . <eos>\n",
      "0.02984745896009824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bipin/anaconda3/envs/pytorch/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    }
   ],
   "source": [
    "#i = 188\n",
    "#input_sentence  = multi30k_data.src_lines[i]\n",
    "#input_sentence  = lines_de[i]\n",
    "\n",
    "#inp = \n",
    "from torchtext.data import Field\n",
    "#train_iter = multi30k_data.train_batch()\n",
    "inp, out = next(train_iter)\n",
    "target_output   = \" \".join([ multi30k_data.trg_lang.vocab.itos[i] for i in out ]) \n",
    "tout = translate2( encoder, decoder, inp )\n",
    "\n",
    "output_sentence = \" \".join([ multi30k_data.trg_lang.vocab.itos[i] for i in tout ])\n",
    "print(target_output)\n",
    "#print(multi30k_data__.trg_lines[i])\n",
    "print(output_sentence)\n",
    "print( sentence_bleu( [target_output.split(' ')], output_sentence.split(' ') , smoothing_function=SmoothingFunction().method1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "npzWULkpCHWA"
   },
   "outputs": [],
   "source": [
    "#train_iter = multi30k_data.val_batch()\n",
    "#inp, out = next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "def eval_val(encoder, decoder, multi30k_data ) :\n",
    "    test_iter = multi30k_data.train_batch()\n",
    "    bleu_score = 0\n",
    "    count = 0\n",
    "    for inp, out in test_iter :\n",
    "        target_output   = \" \".join([ multi30k_data.trg_lang.vocab.itos[i] for i in out ]) \n",
    "        tout = translate2( encoder, decoder, inp )\n",
    "        output_sentence = \" \".join([ multi30k_data.trg_lang.vocab.itos[i] for i in tout ])\n",
    "        bleu_score += sentence_bleu( [target_output.split(' ')], output_sentence.split(' '), \n",
    "                                    smoothing_function=SmoothingFunction().method1)\n",
    "        count += 1\n",
    "    return bleu_score/float(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38746669997529"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_val(encoder, decoder, multi30k_data )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pytorch_nmt_with_attn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
