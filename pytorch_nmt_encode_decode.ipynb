{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#for monitoring\n",
    "from time import time\n",
    "#for parsing the data filename\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi30k_data import *\n",
    "from encoder_decoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeDecodeRun :\n",
    "    def __init__(self, encoder, decoder) :\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        #these values will be filled by the encoders.\n",
    "        self.g = None\n",
    "        self.attn_values = None\n",
    "        self.out = None\n",
    "        \n",
    "        if isinstance(encoder, EncoderSimple) :\n",
    "            self.run_encoder = self.run_simple_encoder\n",
    "        \n",
    "        if isinstance(encoder, EncoderRNN) :\n",
    "            self.run_encoder = self.run_rnn_encoder\n",
    "            \n",
    "        if isinstance(decoder, DecoderRNN) :\n",
    "            self.run_decoder = self.run_rnn_decoder\n",
    "            \n",
    "        if isinstance(decoder, AttnDecoderRNN) :\n",
    "            self.run_decoder = self.run_attn_decoder \n",
    "    \n",
    "    def run_simple_encoder(self, x ) :\n",
    "        self.out = self.encoder(x)\n",
    "        self.g = self.out.view(1,1,-1)\n",
    "        self.attn_values = self.encoder.embedded\n",
    "        \n",
    "        \n",
    "    def run_rnn_encoder(self, x ) :\n",
    "        self.g = self.encoder.init_hidden()\n",
    "        \n",
    "        self.out, self.g = self.encoder(x, self.g )\n",
    "        self.g.detach_()\n",
    "        self.attn_values = self.out\n",
    "        \n",
    "        \n",
    "    def run_rnn_decoder(self, yi ) :\n",
    "            #for i in range(1) :\n",
    "            scores, self.g = self.decoder( yi, self.g)\n",
    "            #print(scores.shape)\n",
    "            #print(next_word.shape)\n",
    "            return scores\n",
    "    \n",
    "    def run_attn_decoder(self, yi ) :\n",
    "        #self.attn_values is of shape (n,d)\n",
    "        #we need it as (MAX_LENGTH, d) witht he first n filled\n",
    "        max_length = self.decoder.max_length\n",
    "        values_to_attend = torch.zeros(max_length, self.decoder.hidden_size, device=device)\n",
    "        for i in range(self.attn_values.shape[0]) :\n",
    "            values_to_attend[i] = self.attn_values[i][0]\n",
    "                \n",
    "        scores, self.g, _ = decoder( yi, self.g, values_to_attend )\n",
    "        #print(scores.shape)\n",
    "        #print(next_word.shape)\n",
    "        return scores\n",
    "\n",
    "def train(encdecrun, encoder_optimizer, decoder_optimizer, criterion, train_iter ) :\n",
    "    start = time()\n",
    "    \n",
    "    loss_db = []\n",
    "    for x, y in train_iter :\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        loss = 0\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        #h = encoder.initHidden().to(device)\n",
    "        #h.detach_()\n",
    "        encdecrun.run_encoder( x )\n",
    "    \n",
    "        #g = torch.sum( encoder_outputs, dim=0 ).view(1,1,-1)\n",
    "        \n",
    "        y = y.detach()\n",
    "        y_len = y.shape[0] #size of sequence\n",
    "        for i in range(y_len - 1) :\n",
    "            scores = encdecrun.run_decoder( y[i] )\n",
    "            loss += criterion(scores, y[i+1] )\n",
    "\n",
    "        loss.backward()\n",
    "        loss_db.append( float(loss) )\n",
    "                \n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "    end = time()\n",
    "    print (end-start)\n",
    "    return loss_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/SPREADTRUM/bipin.vijayasenan/anaconda3/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    }
   ],
   "source": [
    "train_iter = multi30k_data.val_batch(device=device)\n",
    "x, y = next(train_iter)\n",
    "x = x.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderSimple(\n",
      "  (embedding): Embedding(5499, 256)\n",
      ")\n",
      "DecoderRNN(\n",
      "  (embedding): Embedding(10839, 256)\n",
      "  (gru): GRU(256, 256)\n",
      "  (linear): Linear(in_features=256, out_features=10839, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "#encoder = EncoderRNN(len(multi30k_data.src_lang.vocab), hidden_size).to(device)\n",
    "n_src_vocab = len(multi30k_data.src_lang.vocab)\n",
    "n_trg_vocab = len(multi30k_data.trg_lang.vocab)\n",
    "\n",
    "encoder = EncoderSimple(n_src_vocab, hidden_size).to(device)\n",
    "#encoder = EncoderRNN(n_src_vocab, hidden_size).to(device)\n",
    "\n",
    "decoder = DecoderRNN(hidden_size, n_trg_vocab).to(device)\n",
    "\n",
    "#decoder = AttnDecoderRNN(hidden_size, len(multi30k_data.trg_lang.vocab), max_length=50  ).to(device)\n",
    "\n",
    "print(encoder)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "#encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "encoder_optimizer = optim.Adam( filter(lambda p: p.requires_grad, encoder.parameters()) , lr=learning_rate)\n",
    "\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "#criterion = nn.NLLLoss().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encdecrun = EncodeDecodeRun(encoder,decoder)\n",
    "#a = encdecrun.run_encoder( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us have a smaple run\n",
    "a = encdecrun.run_encoder( x )\n",
    "\n",
    "encoder_optimizer.zero_grad()\n",
    "decoder_optimizer.zero_grad()\n",
    "\n",
    "scores = encdecrun.run_decoder( y[1] )\n",
    "loss = criterion(scores, y[2] )\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "encoder_optimizer.step()\n",
    "decoder_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.612107515335083\n",
      "mean iteration loss 69.13144373130798\n",
      "15.626079082489014\n",
      "mean iteration loss 45.554151527404784\n",
      "16.983951807022095\n",
      "mean iteration loss 30.358322249889373\n",
      "18.070173501968384\n",
      "mean iteration loss 17.951374409914017\n",
      "17.132532596588135\n",
      "mean iteration loss 10.057482401520014\n"
     ]
    }
   ],
   "source": [
    "avg_loss = []\n",
    "\n",
    "for _ in range(5) :\n",
    "    l = train(encdecrun, encoder_optimizer, decoder_optimizer, criterion, multi30k_data.train_batch(n_data=1000) )\n",
    "    m = np.mean(l)\n",
    "    print(\"mean iteration loss\", m)\n",
    "    avg_loss.append( m )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f57445d0e10>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_loss)\n",
    "#plt.plot(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#j = [ np.mean(l[i:i+100]) for i in range(200) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> Three dogs playing in the snow . <eos>\n",
      "<sos> Three men playing with Frisbee . <eos>\n",
      "0.07751502105431508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/SPREADTRUM/bipin.vijayasenan/anaconda3/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Field\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "#train_iter = multi30k_data.val_batch()\n",
    "#for _ in range(100) : next(train_iter)\n",
    "inp, out = next(train_iter)\n",
    "#inp = inp.squeeze()\n",
    "out = out.squeeze()\n",
    "target_output   = \" \".join([ multi30k_data.trg_lang.vocab.itos[i] for i in out ]) \n",
    "tout = translate( encdecrun, inp )\n",
    "\n",
    "output_sentence = \" \".join([ multi30k_data.trg_lang.vocab.itos[i] for i in tout ])\n",
    "print(target_output)\n",
    "#print(multi30k_data__.trg_lines[i])\n",
    "print(output_sentence)\n",
    "print( sentence_bleu( [target_output.split(' ')], output_sentence.split(' ') , smoothing_function=SmoothingFunction().method1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug_list = []\n",
    "def translate( encdecrun, x ) :\n",
    "    debug_list = [] #XXX\n",
    "    x = x.to(device)\n",
    "    \n",
    "    out = encdecrun.run_encoder( x )\n",
    "    \n",
    "    #first input is SOS\n",
    "    next_word = x[0][0].view(1,1,1)\n",
    "    predicted_target = []\n",
    "    for i in range(25) :        \n",
    "        scores = encdecrun.run_decoder( next_word )\n",
    "        predicted_target.append( next_word.item() )\n",
    "        if next_word.item() == 3 : #in_data.trg_lang.EOS_token :\n",
    "            break\n",
    "        #now we make the next_word from current_word\n",
    "        v, next_word = scores.topk(1) #return value and index\n",
    "\n",
    "        \n",
    "    return predicted_target    \n",
    "    #return \" \".join([ in_data.trg_lang.itos[i] for i in predicted_target ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_val(encdecrun, test_iter ) :\n",
    "    #test_iter = multi30k_data.train_batch()\n",
    "    bleu_score = 0\n",
    "    count = 0\n",
    "    for inp, out in test_iter :\n",
    "        target_output   = \" \".join([ multi30k_data.trg_lang.vocab.itos[i] for i in out ]) \n",
    "        tout = translate( encdecrun, inp )\n",
    "        output_sentence = \" \".join([ multi30k_data.trg_lang.vocab.itos[i] for i in tout ])\n",
    "        bleu_score += sentence_bleu( [target_output.split(' ')], output_sentence.split(' '), \n",
    "                                    smoothing_function=SmoothingFunction().method1)\n",
    "        count += 1\n",
    "    return bleu_score/float(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08294689595420113"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_val(encdecrun, multi30k_data.val_batch())\n",
    "#Training on trianing set (first 1000), eval on val set\n",
    "# RNN Encoder Decoder\n",
    "#5 iter : 0.04284566223317566\n",
    "\n",
    "#Training on trianing set (first 1000), eval on val set\n",
    "# SimpleEncoder RNNDecoder\n",
    "#5 iter : 0.08086874335565286\n",
    "\n",
    "#0 iter : 0.007594141420805346 ( No training; random init )\n",
    "#1 iter (2K) : 0.08813359634828569\n",
    "#1 iter (20K): 0.12253828240795721\n",
    "#20 iter (20K) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8642076513814061"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_val(encdecrun, multi30k_data.train_batch(n_data=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EncoderRNN, AttnDecoderRNN\n",
    "#torch.save(encoder.state_dict(), 'encoder.pt')\n",
    "#torch.save(decoder.state_dict(), 'decoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
